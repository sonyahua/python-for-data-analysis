{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch 11. Financial and Economic Data Applications\n",
    "\n",
    "Python is advantageous for interactive analysis environment as well as building robust systems in the fraction of the time it would take in Java or C++. It's also a glue layer by building Python interfaces to legacy libraries built in C or C++. \n",
    "\n",
    "**Cross section data**: data at a fixed point in time\n",
    "\n",
    "**Panel data**: cross sectional data at multiple points in time over multiple variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series and Cross-Section Alignment\n",
    "\n",
    "**Data alignment** problems: Issues with aligning time series data especially when indexes don't line up perfectly. Aligning data by hand is tedious and prone to errors. \n",
    "\n",
    "pandas automatically aligns data in arithmetic operations. \n",
    "\n",
    "For example, we want to create a weighted average price per stock based on price * volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sonya\\Documents\\Python for Data Analysis\\data\\ch11\n",
      "              AA  AAPL    GE    IBM   JNJ  MSFT   PEP     SPX   XOM\n",
      "1990-02-01  4.98  7.86  2.87  16.79  4.27  0.51  6.04  328.79  6.12\n",
      "1990-02-02  5.04  8.00  2.87  16.89  4.37  0.51  6.09  330.92  6.24\n",
      "1990-02-05  5.07  8.18  2.87  17.32  4.34  0.51  6.05  331.85  6.25\n",
      "1990-02-06  5.01  8.12  2.88  17.56  4.32  0.51  6.15  329.66  6.23\n",
      "1990-02-07  5.04  7.77  2.91  17.93  4.38  0.51  6.17  333.75  6.33\n",
      "                   AA        AAPL          GE         IBM        JNJ  \\\n",
      "1990-02-01  2185600.0   4193200.0  14457600.0   6903600.0  5942400.0   \n",
      "1990-02-02  3103200.0   4248800.0  15302400.0   6064400.0  4732800.0   \n",
      "1990-02-05  1792800.0   3653200.0   9134400.0   5299200.0  3950400.0   \n",
      "1990-02-06  2205600.0   2640000.0  14389200.0  10808000.0  3761600.0   \n",
      "1990-02-07  3592800.0  11180800.0  18704400.0  12057600.0  5458400.0   \n",
      "\n",
      "                   MSFT        PEP          SPX        XOM  \n",
      "1990-02-01   89193600.0  2954400.0  154580000.0  2916400.0  \n",
      "1990-02-02   71395200.0  2424000.0  164400000.0  4250000.0  \n",
      "1990-02-05   59731200.0  2225400.0  130950000.0  5880800.0  \n",
      "1990-02-06   81964800.0  3270000.0  134070000.0  4750800.0  \n",
      "1990-02-07  134150400.0  4332600.0  186710000.0  4124800.0  \n"
     ]
    }
   ],
   "source": [
    "% cd \"C:\\Users\\sonya\\Documents\\Python for Data Analysis\\data\\ch11\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame, Series\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get a list of files from current directory\n",
    "os.listdir(os.curdir) \n",
    "\n",
    "# retrieve files\n",
    "\n",
    "prices = pd.read_csv(\"stock_px.csv\", parse_dates=True, index_col=[0])\n",
    "volume= pd.read_csv(\"volume.csv\", parse_dates=True, index_col=[0])\n",
    "print prices.head()\n",
    "print volume.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      AA          AAPL            GE          IBM  \\\n",
      "2011-01-03  6.560527e+08  5.239438e+09  9.424551e+08  670359318.0   \n",
      "2011-01-04  1.241720e+09  3.656978e+09  1.434994e+09  737610777.0   \n",
      "2011-01-05  7.951502e+08  3.047984e+09  9.335545e+08  676207906.0   \n",
      "2011-01-06  6.133920e+08  3.580789e+09  7.178822e+08  738185976.0   \n",
      "2011-01-07  5.928198e+08  3.744511e+09  1.030910e+09  604018985.0   \n",
      "\n",
      "                    JNJ          MSFT          PEP           SPX           XOM  \n",
      "2011-01-03  911263864.0  1.467567e+09  436151898.0  5.452087e+12  1.708474e+09  \n",
      "2011-01-04  761643247.0  1.499962e+09  504861603.0  6.092413e+12  1.474098e+09  \n",
      "2011-01-05  729806535.0  1.621284e+09  675654052.0  6.082706e+12  1.214829e+09  \n",
      "2011-01-06  468225360.0  2.489319e+09  499702637.0  6.170657e+12  1.664169e+09  \n",
      "2011-01-07  675729408.0  2.070499e+09  317902599.0  6.310594e+12  1.433433e+09  \n"
     ]
    }
   ],
   "source": [
    "# preview arithmetic operation\n",
    "\n",
    "print (prices.loc['2011'] * volume.loc['2011']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AA        14.703328\n",
       "AAPL     359.343000\n",
       "GE        17.941365\n",
       "IBM      166.440791\n",
       "JNJ       62.530314\n",
       "MSFT      25.841639\n",
       "PEP       64.216647\n",
       "SPX     1269.936785\n",
       "XOM       78.134461\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate volume weighted average price per stock for 2011\n",
    "\n",
    "vwap = (prices.loc['2011'] * volume.loc['2011']).sum() / volume.loc['2011'].sum()\n",
    "vwap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(               AA    AAPL     GE     IBM    JNJ   MSFT    PEP      SPX    XOM\n",
       " 1990-02-01   4.98    7.86   2.87   16.79   4.27   0.51   6.04   328.79   6.12\n",
       " 1990-02-02   5.04    8.00   2.87   16.89   4.37   0.51   6.09   330.92   6.24\n",
       " 1990-02-05   5.07    8.18   2.87   17.32   4.34   0.51   6.05   331.85   6.25\n",
       " 1990-02-06   5.01    8.12   2.88   17.56   4.32   0.51   6.15   329.66   6.23\n",
       " 1990-02-07   5.04    7.77   2.91   17.93   4.38   0.51   6.17   333.75   6.33\n",
       " 1990-02-08   5.04    7.71   2.92   17.86   4.46   0.51   6.22   332.96   6.35\n",
       " 1990-02-09   5.06    8.00   2.94   17.82   4.49   0.52   6.24   333.62   6.37\n",
       " 1990-02-12   4.96    7.94   2.89   17.58   4.46   0.52   6.23   330.08   6.22\n",
       " 1990-02-13   4.91    8.06   2.88   17.95   4.43   0.52   6.09   331.02   6.23\n",
       " 1990-02-14   4.94    8.00   2.89   18.04   4.47   0.52   6.10   332.01   6.20\n",
       " 1990-02-15   4.99    8.00   2.91   18.04   4.54   0.53   6.15   334.89   6.40\n",
       " 1990-02-16   5.10    7.91   2.88   17.99   4.47   0.53   6.11   332.72   6.33\n",
       " 1990-02-20   5.04    7.85   2.83   17.88   4.39   0.55   6.01   327.99   6.25\n",
       " 1990-02-21   5.01    7.97   2.81   18.23   4.33   0.52   5.91   327.67   6.28\n",
       " 1990-02-22   5.06    7.73   2.82   17.95   4.28   0.53   5.87   325.70   6.22\n",
       " 1990-02-23   5.07    7.79   2.81   17.84   4.20   0.53   5.88   324.15   6.22\n",
       " 1990-02-26   5.13    7.97   2.84   18.08   4.30   0.54   5.93   328.67   6.37\n",
       " 1990-02-27   5.16    7.85   2.88   18.04   4.30   0.53   6.00   330.26   6.38\n",
       " 1990-02-28   5.22    7.97   2.89   18.06   4.32   0.54   6.06   331.89   6.20\n",
       " 1990-03-01   5.26    8.03   2.88   18.08   4.35   0.55   5.98   332.74   6.13\n",
       " 1990-03-02   5.41    7.91   2.92   18.23   4.43   0.57   5.89   335.54   6.17\n",
       " 1990-03-05   5.39    8.08   2.89   18.25   4.36   0.57   5.89   333.74   6.10\n",
       " 1990-03-06   5.40    8.26   2.92   18.39   4.45   0.57   5.97   337.93   6.22\n",
       " 1990-03-07   5.36    8.29   2.93   18.34   4.45   0.56   6.06   336.95   6.13\n",
       " 1990-03-08   5.34    8.61   2.95   18.60   4.50   0.58   6.18   340.27   6.17\n",
       " 1990-03-09   5.33    8.64   2.93   18.52   4.48   0.58   6.10   337.93   6.12\n",
       " 1990-03-12   5.34    8.58   2.92   18.73   4.46   0.59   6.22   338.67   6.13\n",
       " 1990-03-13   5.29    8.64   2.90   18.47   4.38   0.58   6.18   336.00   6.02\n",
       " 1990-03-14   5.28    8.67   2.95   18.47   4.44   0.59   6.15   336.87   6.13\n",
       " 1990-03-15   5.36    8.61   2.96   18.60   4.58   0.61   6.18   338.07   6.18\n",
       " ...           ...     ...    ...     ...    ...    ...    ...      ...    ...\n",
       " 2011-09-02  12.04  374.05  15.61  166.98  64.07  25.80  63.30  1173.97  72.14\n",
       " 2011-09-06  11.77  379.74  15.11  165.11  64.64  25.51  62.45  1165.24  71.15\n",
       " 2011-09-07  12.25  383.93  15.65  167.31  65.43  26.00  61.62  1198.62  73.65\n",
       " 2011-09-08  12.03  384.14  15.44  165.25  64.95  26.22  61.34  1185.90  72.82\n",
       " 2011-09-09  11.58  377.48  14.95  161.37  63.64  25.74  59.99  1154.23  71.01\n",
       " 2011-09-12  11.55  379.94  14.87  162.42  63.59  25.89  60.14  1162.27  71.84\n",
       " 2011-09-13  11.63  384.62  15.26  163.43  63.61  26.04  60.54  1172.87  71.65\n",
       " 2011-09-14  11.73  389.30  15.64  167.24  63.73  26.50  61.58  1188.68  72.64\n",
       " 2011-09-15  11.98  392.96  16.08  170.09  64.40  26.99  63.22  1209.11  74.01\n",
       " 2011-09-16  11.97  400.50  16.33  172.99  64.59  27.12  62.05  1216.01  74.55\n",
       " 2011-09-19  11.58  411.63  16.18  173.13  64.14  27.21  60.56  1204.09  73.70\n",
       " 2011-09-20  11.25  413.45  16.04  174.72  64.22  26.98  60.39  1202.09  74.01\n",
       " 2011-09-21  10.84  412.14  15.38  173.02  63.13  25.99  60.79  1166.76  71.97\n",
       " 2011-09-22  10.11  401.82  15.04  168.62  61.92  25.06  60.92  1129.56  69.24\n",
       " 2011-09-23  10.07  404.30  15.21  169.34  61.59  25.06  60.34  1136.43  69.31\n",
       " 2011-09-26  10.45  403.17  15.57  174.51  62.69  25.44  61.89  1162.95  71.72\n",
       " 2011-09-27  10.48  399.26  15.76  177.71  63.82  25.67  62.43  1175.38  72.91\n",
       " 2011-09-28   9.97  397.01  15.45  177.55  63.25  25.58  61.97  1151.06  72.07\n",
       " 2011-09-29  10.06  390.57  15.86  179.17  63.90  25.45  62.58  1160.40  73.88\n",
       " 2011-09-30   9.57  381.32  15.22  174.87  63.69  24.89  61.90  1131.42  72.63\n",
       " 2011-10-03   8.90  374.60  14.69  173.29  62.08  24.53  60.29  1099.23  71.15\n",
       " 2011-10-04   9.12  372.50  14.86  174.74  62.17  25.34  60.45  1123.95  72.83\n",
       " 2011-10-05   9.37  378.25  15.27  176.85  62.35  25.89  60.29  1144.03  73.95\n",
       " 2011-10-06   9.88  377.37  15.53  181.69  62.81  26.34  60.57  1164.97  73.89\n",
       " 2011-10-07   9.71  369.80  15.50  182.39  63.13  26.25  61.02  1155.46  73.56\n",
       " 2011-10-10  10.09  388.81  16.14  186.62  64.43  26.94  61.87  1194.89  76.28\n",
       " 2011-10-11  10.30  400.29  16.14  185.00  63.96  27.00  60.95  1195.54  76.27\n",
       " 2011-10-12  10.05  402.19  16.40  186.12  64.33  26.96  62.70  1207.25  77.16\n",
       " 2011-10-13  10.10  408.43  16.22  186.82  64.23  27.18  62.36  1203.66  76.37\n",
       " 2011-10-14  10.26  422.00  16.60  190.53  64.72  27.27  62.24  1224.58  78.11\n",
       " \n",
       " [5472 rows x 9 columns],\n",
       "                      AA        AAPL           GE         IBM         JNJ  \\\n",
       " 1990-02-01    2185600.0   4193200.0   14457600.0   6903600.0   5942400.0   \n",
       " 1990-02-02    3103200.0   4248800.0   15302400.0   6064400.0   4732800.0   \n",
       " 1990-02-05    1792800.0   3653200.0    9134400.0   5299200.0   3950400.0   \n",
       " 1990-02-06    2205600.0   2640000.0   14389200.0  10808000.0   3761600.0   \n",
       " 1990-02-07    3592800.0  11180800.0   18704400.0  12057600.0   5458400.0   \n",
       " 1990-02-08    2777600.0   6680000.0   16513200.0   7932000.0   8669600.0   \n",
       " 1990-02-09    1582400.0   6004400.0   13785600.0   5061600.0   3277600.0   \n",
       " 1990-02-12    2137600.0   2695600.0   15488400.0   4766400.0   2564800.0   \n",
       " 1990-02-13    5026400.0   3653600.0   20540400.0   7168400.0   3635200.0   \n",
       " 1990-02-14    2588800.0   3448000.0   10269600.0   6006800.0   3706400.0   \n",
       " 1990-02-15    4604000.0   3509200.0   12546000.0   5704000.0   3321600.0   \n",
       " 1990-02-16    7072800.0   4556400.0   21541200.0   8805600.0   5688800.0   \n",
       " 1990-02-20    2692800.0   4402400.0   22068000.0   5599600.0   4868800.0   \n",
       " 1990-02-21    2503200.0   6283600.0   20756400.0   8096400.0   5700000.0   \n",
       " 1990-02-22    5733600.0   6976800.0   17676000.0   9185600.0   3635200.0   \n",
       " 1990-02-23    1409600.0   5375600.0   14785200.0   6251600.0   8396000.0   \n",
       " 1990-02-26    1483200.0   2844800.0   16886400.0   5486000.0   4200000.0   \n",
       " 1990-02-27    2268000.0   2642000.0   20508000.0   6890800.0   4824000.0   \n",
       " 1990-02-28    3841600.0   3918800.0   21376800.0   5761200.0   6113600.0   \n",
       " 1990-03-01    5676000.0   7283200.0   27291600.0   4490800.0   3041600.0   \n",
       " 1990-03-02    4727200.0   3761200.0   20215200.0   5690000.0   4372800.0   \n",
       " 1990-03-05    1647200.0   6537600.0   18685200.0   5509200.0   4567200.0   \n",
       " 1990-03-06    2151200.0   5578800.0   18181200.0   5100800.0   4138400.0   \n",
       " 1990-03-07    3192800.0   7301200.0   12364800.0   6158400.0   3178400.0   \n",
       " 1990-03-08    2243200.0   8013600.0   16664400.0   6947600.0   3357600.0   \n",
       " 1990-03-09    2673600.0   8248800.0   13256400.0   7003200.0   3113600.0   \n",
       " 1990-03-12    2034400.0   5864400.0   12255600.0   6051200.0   2910400.0   \n",
       " 1990-03-13    2265600.0   5321200.0   14433600.0   8300800.0   3255200.0   \n",
       " 1990-03-14    4244800.0   3654800.0   15728400.0   4990800.0   4242400.0   \n",
       " 1990-03-15    5807200.0   4302000.0   20035200.0   5328000.0   8232800.0   \n",
       " ...                 ...         ...          ...         ...         ...   \n",
       " 2011-09-02   17957800.0  15676400.0   61743900.0   4979100.0  13713600.0   \n",
       " 2011-09-06   23960600.0  18173500.0   97466600.0   5761200.0  15848300.0   \n",
       " 2011-09-07   16645700.0  12492000.0   60239400.0   6796600.0  10759700.0   \n",
       " 2011-09-08   15735500.0  14839800.0  117920800.0   6027200.0  15551500.0   \n",
       " 2011-09-09   24972700.0  20171900.0  144441000.0   6743900.0  17008200.0   \n",
       " 2011-09-12   28990500.0  16697300.0  169797200.0   5247200.0  13448200.0   \n",
       " 2011-09-13   23014600.0  15734300.0   83300700.0   4723800.0  11595300.0   \n",
       " 2011-09-14   25422200.0  19084600.0   91340600.0   6980700.0  13429500.0   \n",
       " 2011-09-15   19886100.0  14887800.0   67326400.0   5464400.0  10625800.0   \n",
       " 2011-09-16   23730300.0  24915500.0   89205000.0  11048100.0  15688800.0   \n",
       " 2011-09-19   23674000.0  29375800.0   54153600.0   4755600.0   8571800.0   \n",
       " 2011-09-20   22887400.0  27689900.0   56235500.0   6209600.0  10874800.0   \n",
       " 2011-09-21   27445300.0  21612300.0   74360800.0   7043100.0  10041300.0   \n",
       " 2011-09-22   61129500.0  34562600.0  113698400.0   8195600.0  19456900.0   \n",
       " 2011-09-23   39749700.0  19509900.0   65513500.0   5586600.0  10983700.0   \n",
       " 2011-09-26   32227800.0  29015500.0   93900700.0   6745700.0  10561700.0   \n",
       " 2011-09-27   30923100.0  22566600.0   80391600.0   7638800.0  13118200.0   \n",
       " 2011-09-28   33850700.0  15344200.0   57431600.0   7732200.0   8964200.0   \n",
       " 2011-09-29   33805300.0  23253100.0   60693300.0   6944300.0   8923300.0   \n",
       " 2011-09-30   37616400.0  19558600.0   75779600.0   7807400.0  14556100.0   \n",
       " 2011-10-03   53880500.0  23876300.0   92683100.0   9042600.0  16891100.0   \n",
       " 2011-10-04   49910200.0  44035800.0  111955700.0   9175200.0  18192000.0   \n",
       " 2011-10-05   42472800.0  28075700.0   79536800.0   5851700.0  15405200.0   \n",
       " 2011-10-06   69681700.0  29008700.0   64943200.0   7180900.0   9595400.0   \n",
       " 2011-10-07   44873300.0  19123500.0   65569100.0   6842600.0  12361600.0   \n",
       " 2011-10-10   29555500.0  15769200.0   56154800.0   5784800.0   7104000.0   \n",
       " 2011-10-11   54708100.0  21609800.0   45999500.0   5330500.0   7628700.0   \n",
       " 2011-10-12  109803600.0  22206600.0   61755100.0   5338200.0   9375100.0   \n",
       " 2011-10-13   42546500.0  15177900.0   46124800.0   4399200.0   7781100.0   \n",
       " 2011-10-14   38184400.0  20450000.0   45134200.0   5368200.0   6678800.0   \n",
       " \n",
       "                    MSFT         PEP           SPX         XOM  \n",
       " 1990-02-01   89193600.0   2954400.0  1.545800e+08   2916400.0  \n",
       " 1990-02-02   71395200.0   2424000.0  1.644000e+08   4250000.0  \n",
       " 1990-02-05   59731200.0   2225400.0  1.309500e+08   5880800.0  \n",
       " 1990-02-06   81964800.0   3270000.0  1.340700e+08   4750800.0  \n",
       " 1990-02-07  134150400.0   4332600.0  1.867100e+08   4124800.0  \n",
       " 1990-02-08   95225600.0   5133000.0  1.762400e+08   5651200.0  \n",
       " 1990-02-09   62380800.0   2628600.0  1.469100e+08   3384800.0  \n",
       " 1990-02-12   56086400.0   1996200.0  1.183900e+08   2698000.0  \n",
       " 1990-02-13   58752000.0   4217400.0  1.444900e+08   3564800.0  \n",
       " 1990-02-14   35868800.0   2660400.0  1.385300e+08   2830000.0  \n",
       " 1990-02-15   89494400.0   2427600.0  1.746200e+08   4054400.0  \n",
       " 1990-02-16   70876800.0   2871000.0  1.668400e+08   7154400.0  \n",
       " 1990-02-20  132652800.0   2303400.0  1.473000e+08   4064400.0  \n",
       " 1990-02-21  103347200.0   4482000.0  1.592400e+08   4263200.0  \n",
       " 1990-02-22   60809600.0   4706400.0  1.843200e+08   5007600.0  \n",
       " 1990-02-23   56851200.0   2362800.0  1.484900e+08   4040000.0  \n",
       " 1990-02-26   69219200.0   4060200.0  1.489000e+08   4702000.0  \n",
       " 1990-02-27   62019200.0   3374400.0  1.525900e+08   4600800.0  \n",
       " 1990-02-28   39312000.0   4620600.0  1.844000e+08  10029200.0  \n",
       " 1990-03-01   76867200.0   3512400.0  1.579300e+08   5619200.0  \n",
       " 1990-03-02  100208000.0  11029800.0  1.643300e+08   5642000.0  \n",
       " 1990-03-05   75526400.0   5386800.0  1.401100e+08   4534400.0  \n",
       " 1990-03-06   68630400.0   4900800.0  1.436400e+08   5135600.0  \n",
       " 1990-03-07   47606400.0   2929200.0  1.635800e+08   4808000.0  \n",
       " 1990-03-08   88976000.0   4893600.0  1.709000e+08   3220000.0  \n",
       " 1990-03-09   75744000.0   3667800.0  1.504100e+08   3911200.0  \n",
       " 1990-03-12   68873600.0   2365800.0  1.147900e+08   2858000.0  \n",
       " 1990-03-13   85203200.0   2217600.0  1.454400e+08   5596800.0  \n",
       " 1990-03-14  130966400.0   3876000.0  1.450600e+08   5852000.0  \n",
       " 1990-03-15   81676800.0   1514400.0  1.444100e+08   2989200.0  \n",
       " ...                 ...         ...           ...         ...  \n",
       " 2011-09-02   43894400.0   5790000.0  4.401740e+09  21071800.0  \n",
       " 2011-09-06   54929300.0   8216000.0  5.103980e+09  25416300.0  \n",
       " 2011-09-07   41961000.0  14915300.0  4.441040e+09  23108400.0  \n",
       " 2011-09-08   65811900.0  11827200.0  4.465170e+09  22434800.0  \n",
       " 2011-09-09   64529200.0  14838300.0  4.586370e+09  27969100.0  \n",
       " 2011-09-12   55046100.0  11253500.0  5.168550e+09  26205800.0  \n",
       " 2011-09-13   48792300.0   9470700.0  4.681370e+09  22825400.0  \n",
       " 2011-09-14   66739200.0  10606900.0  4.986740e+09  26042800.0  \n",
       " 2011-09-15   67808300.0  18666400.0  4.479730e+09  21858300.0  \n",
       " 2011-09-16   89681500.0  16669100.0  5.248890e+09  34652600.0  \n",
       " 2011-09-19   52324900.0  13587000.0  4.254190e+09  19822500.0  \n",
       " 2011-09-20   49211900.0   9630200.0  4.315610e+09  20420000.0  \n",
       " 2011-09-21   72750700.0  14350400.0  4.728550e+09  23806200.0  \n",
       " 2011-09-22   96278300.0  16341000.0  6.703140e+09  43223000.0  \n",
       " 2011-09-23   64768100.0  11139000.0  5.639930e+09  26583200.0  \n",
       " 2011-09-26   51035200.0  10312400.0  4.762830e+09  30342400.0  \n",
       " 2011-09-27   55620700.0   7991500.0  5.548130e+09  26689900.0  \n",
       " 2011-09-28   60736200.0   7054300.0  4.787920e+09  26026500.0  \n",
       " 2011-09-29   63407300.0   6609100.0  5.285740e+09  27713900.0  \n",
       " 2011-09-30   54060500.0   7405600.0  4.416790e+09  30917000.0  \n",
       " 2011-10-03   64592500.0  10573100.0  5.670340e+09  31004200.0  \n",
       " 2011-10-04   83470600.0  11390500.0  3.714670e+09  36454500.0  \n",
       " 2011-10-05   94042600.0   9194000.0  2.510620e+09  28239800.0  \n",
       " 2011-10-06   55111400.0   8023900.0  5.098330e+09  24869800.0  \n",
       " 2011-10-07   52741600.0   7909800.0  5.580380e+09  23573900.0  \n",
       " 2011-10-10   41815300.0   5985600.0  4.446800e+09  20455700.0  \n",
       " 2011-10-11   38826200.0  10261900.0  4.424500e+09  17862100.0  \n",
       " 2011-10-12   52489800.0  13796200.0  5.355360e+09  22239000.0  \n",
       " 2011-10-13   43823500.0   6887300.0  4.436270e+09  19540300.0  \n",
       " 2011-10-14   50947700.0   8736600.0  4.116690e+09  17870600.0  \n",
       " \n",
       " [5472 rows x 9 columns])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To align dates by hand, use DataFrame's align method which returns a tuple of reindexedvversions of the 2 objects\n",
    "\n",
    "prices.align(volume, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important feature is constructing a df from a collection of potentially differently indexed Series. We can pass a dictionary that maps the columns of df to each series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  three  two\n",
      "a  0.0    1.0  NaN\n",
      "b  1.0    NaN  1.0\n",
      "c  2.0    2.0  2.0\n",
      "d  NaN    NaN  0.0\n",
      "e  NaN    NaN  3.0\n",
      "f  NaN    0.0  NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>one</th>\n",
       "      <th>three</th>\n",
       "      <th>two</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   one  three  two\n",
       "f  NaN    0.0  NaN\n",
       "a  0.0    1.0  NaN\n",
       "c  2.0    2.0  2.0\n",
       "e  NaN    NaN  3.0\n",
       "d  NaN    NaN  0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = Series(range(3), index = ['a','b','c'])\n",
    "s2 = Series(range(4), index= ['d','b','c','e'])\n",
    "s3= Series(range(3), index=['f','a','c'])\n",
    "\n",
    "\n",
    "# Dataframe using series\n",
    "print DataFrame({'one': s1, 'two': s2, 'three': s3})\n",
    "\n",
    "# specify the index of the result\n",
    "DataFrame({'one': s1, 'two': s2, 'three':s3}, index=list('faced'))  # list parses the characters of the string into a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations on Time Series of Different Frequencies\n",
    "\n",
    "The 2 main tools for frequency conversion and realignment are `resample` and `reindex`. \n",
    "\n",
    "**resample** converts data to a fixed frequency (i.e. from daily to weekly)\n",
    "\n",
    "**reindex** conforms data to a new index\n",
    "\n",
    "Both methods support **interpolation** or the insertion of something of a different nature into something else. (i.e. forward filling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-06-13    1.600728\n",
       "2012-06-20   -1.766214\n",
       "2012-06-27    0.374528\n",
       "Freq: W-WED, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1 = Series(np.random.randn(3), index=pd.date_range('2012-6-13', periods=3, freq='W-WED'))\n",
    "\n",
    "ts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-06-13    1.600728\n",
       "2012-06-14         NaN\n",
       "2012-06-15         NaN\n",
       "2012-06-18         NaN\n",
       "2012-06-19         NaN\n",
       "2012-06-20   -1.766214\n",
       "2012-06-21         NaN\n",
       "2012-06-22         NaN\n",
       "2012-06-25         NaN\n",
       "2012-06-26         NaN\n",
       "2012-06-27    0.374528\n",
       "Freq: B, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample data to business daily frequency:\n",
    "\n",
    "ts1.resample('B').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward filling values ia common practice with lower frequency data (i.e. weekly) as you compute a time series of values on each timestamp having the latest valid or \"as of\" value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-06-13    1.600728\n",
       "2012-06-14    1.600728\n",
       "2012-06-15    1.600728\n",
       "2012-06-18    1.600728\n",
       "2012-06-19    1.600728\n",
       "2012-06-20   -1.766214\n",
       "2012-06-21   -1.766214\n",
       "2012-06-22   -1.766214\n",
       "2012-06-25   -1.766214\n",
       "2012-06-26   -1.766214\n",
       "2012-06-27    0.374528\n",
       "Freq: B, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1.resample('B').mean().ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling lower frequency data to a higher frequency is a fine solution, but in the more general irregular time series case, it may be a poor fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-06-12    0.769466\n",
       "2012-06-17   -0.644734\n",
       "2012-06-18    0.183820\n",
       "2012-06-21   -0.032836\n",
       "2012-06-22   -0.911538\n",
       "2012-06-29    0.472982\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# irregularly sampled time series from the same general time period\n",
    "\n",
    "dates = pd.DatetimeIndex(['2012-6-12','2012-6-17', '2012-6-18', '2012-6-21','2012-6-22','2012-6-29'])\n",
    "\n",
    "ts2 = Series(np.random.randn(6), index=dates)\n",
    "\n",
    "ts2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to add \"as of\" values in ts1 to ts2, we can 1) resample both to a regular frequency then add or 2) if we want to maintain the date index in ts2, we can use reindex\n",
    "\n",
    "**Reindex**: Conform DataFrame to new index with optional filling logic, placing NA/NaN in locations having no value in the previous index. A new object is produced unless the new index is equivalent to the current one and copy=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-06-12         NaN\n",
       "2012-06-17    1.600728\n",
       "2012-06-18    1.600728\n",
       "2012-06-21   -1.766214\n",
       "2012-06-22   -1.766214\n",
       "2012-06-29    0.374528\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using reindex to pull \"as of\" data in ts1 using ts2 index\n",
    "\n",
    "ts1.reindex(ts2.index, method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-06-12         NaN\n",
       "2012-06-17    0.955994\n",
       "2012-06-18    1.784549\n",
       "2012-06-21   -1.799050\n",
       "2012-06-22   -2.677752\n",
       "2012-06-29    0.847510\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts2 + ts1.reindex(ts2.index, method='ffill')  # Combining data on ts2 index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using periods instead of timestamps\n",
    "\n",
    "Periods provide an alternate way of working with different frequency time series. \n",
    "\n",
    "For example, consider a GDP and inflation dataset. GDP is measured on fiscal year ending in September. Inflation is measured on calendar year ending in December.. We can convert the inflation values to 'Q-SEP' frequency to get the right periods in that frequency. That time series can then be reindexed with foward-filling to match gdp's time index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1984Q2    1.78\n",
      "1984Q3    1.94\n",
      "1984Q4    2.08\n",
      "1985Q1    2.01\n",
      "1985Q2    2.15\n",
      "1985Q3    2.31\n",
      "1985Q4    2.46\n",
      "Freq: Q-SEP, dtype: float64 1982    0.025\n",
      "1983    0.045\n",
      "1984    0.037\n",
      "1985    0.040\n",
      "Freq: A-DEC, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# period ranges with different frequencies\n",
    "\n",
    "gdp = Series([1.78, 1.94, 2.08, 2.01, 2.15, 2.31, 2.46], \n",
    "             index=pd.period_range('1984Q2', periods=7, freq='Q-SEP'))\n",
    "\n",
    "infl = Series([0.025, 0.045, 0.037, 0.04],\n",
    "              index=pd.period_range('1982', periods=4, freq='A-DEC'))\n",
    "\n",
    "print gdp, infl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1983Q1    0.025\n",
       "1984Q1    0.045\n",
       "1985Q1    0.037\n",
       "1986Q1    0.040\n",
       "Freq: Q-SEP, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert period to diff frequency using asfreq\n",
    "infl_q = infl.asfreq('Q-SEP', how='end')\n",
    "infl_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1984Q2    0.045\n",
       "1984Q3    0.045\n",
       "1984Q4    0.045\n",
       "1985Q1    0.037\n",
       "1985Q2    0.037\n",
       "1985Q3    0.037\n",
       "1985Q4    0.037\n",
       "Freq: Q-SEP, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reindex with forward fill to match GDP\n",
    "\n",
    "infl_q.reindex(gdp.index, method='ffill')  # we must specify which column to reindex on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time of Day and \"as of\" Data Selection\n",
    "\n",
    "Suppose we have intraday (occurring within one day) market data and we want to pull prices at a particular time of day on each day of the data. What if the data is irregular and does not fall exactly on the desired time? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-06-01 09:30:00', '2012-06-01 09:31:00',\n",
       "               '2012-06-01 09:32:00', '2012-06-01 09:33:00',\n",
       "               '2012-06-01 09:34:00', '2012-06-01 09:35:00',\n",
       "               '2012-06-01 09:36:00', '2012-06-01 09:37:00',\n",
       "               '2012-06-01 09:38:00', '2012-06-01 09:39:00',\n",
       "               ...\n",
       "               '2012-06-01 15:50:00', '2012-06-01 15:51:00',\n",
       "               '2012-06-01 15:52:00', '2012-06-01 15:53:00',\n",
       "               '2012-06-01 15:54:00', '2012-06-01 15:55:00',\n",
       "               '2012-06-01 15:56:00', '2012-06-01 15:57:00',\n",
       "               '2012-06-01 15:58:00', '2012-06-01 15:59:00'],\n",
       "              dtype='datetime64[ns]', length=390, freq='T')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range('2012-06-01 09:30', '2012-06-01 15:59', freq='T')\n",
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-06-01 09:30:00', '2012-06-01 09:31:00',\n",
       "               '2012-06-01 09:32:00', '2012-06-01 09:33:00',\n",
       "               '2012-06-01 09:34:00', '2012-06-01 09:35:00',\n",
       "               '2012-06-01 09:36:00', '2012-06-01 09:37:00',\n",
       "               '2012-06-01 09:38:00', '2012-06-01 09:39:00',\n",
       "               ...\n",
       "               '2012-06-06 15:50:00', '2012-06-06 15:51:00',\n",
       "               '2012-06-06 15:52:00', '2012-06-06 15:53:00',\n",
       "               '2012-06-06 15:54:00', '2012-06-06 15:55:00',\n",
       "               '2012-06-06 15:56:00', '2012-06-06 15:57:00',\n",
       "               '2012-06-06 15:58:00', '2012-06-06 15:59:00'],\n",
       "              dtype='datetime64[ns]', length=1560, freq=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a 5-day series of 9:30 to 15:59 values\n",
    "rng = rng.append([rng + pd.offsets.BDay(i) for i in range(1,4)])  # business days + time periods \n",
    "rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**np.arange**: For integer arguments the function is equivalent to the Python built-in range function, but returns an ndarray rather than a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-06-01 09:30:00    0.0\n",
      "2012-06-01 09:31:00    1.0\n",
      "2012-06-01 09:32:00    2.0\n",
      "2012-06-01 09:33:00    3.0\n",
      "2012-06-01 09:34:00    4.0\n",
      "dtype: float64 2012-06-06 15:55:00    1555.0\n",
      "2012-06-06 15:56:00    1556.0\n",
      "2012-06-06 15:57:00    1557.0\n",
      "2012-06-06 15:58:00    1558.0\n",
      "2012-06-06 15:59:00    1559.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ts = Series(np.arange(len(rng), dtype=float), index=rng)\n",
    "\n",
    "print ts.head(), ts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-06-01 10:00:00      30.0\n",
       "2012-06-04 10:00:00     420.0\n",
       "2012-06-05 10:00:00     810.0\n",
       "2012-06-06 10:00:00    1200.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import time\n",
    "\n",
    "ts[time(10,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-06-01 10:00:00      30.0\n",
       "2012-06-04 10:00:00     420.0\n",
       "2012-06-05 10:00:00     810.0\n",
       "2012-06-06 10:00:00    1200.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.at_time(time(10,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-06-01 09:30:00       0.0\n",
       "2012-06-01 09:31:00       1.0\n",
       "2012-06-01 09:32:00       2.0\n",
       "2012-06-01 09:33:00       3.0\n",
       "2012-06-01 09:34:00       4.0\n",
       "2012-06-01 09:35:00       5.0\n",
       "2012-06-01 09:36:00       6.0\n",
       "2012-06-01 09:37:00       7.0\n",
       "2012-06-01 09:38:00       8.0\n",
       "2012-06-01 09:39:00       9.0\n",
       "2012-06-01 09:40:00      10.0\n",
       "2012-06-04 09:30:00     390.0\n",
       "2012-06-04 09:31:00     391.0\n",
       "2012-06-04 09:32:00     392.0\n",
       "2012-06-04 09:33:00     393.0\n",
       "2012-06-04 09:34:00     394.0\n",
       "2012-06-04 09:35:00     395.0\n",
       "2012-06-04 09:36:00     396.0\n",
       "2012-06-04 09:37:00     397.0\n",
       "2012-06-04 09:38:00     398.0\n",
       "2012-06-04 09:39:00     399.0\n",
       "2012-06-04 09:40:00     400.0\n",
       "2012-06-05 09:30:00     780.0\n",
       "2012-06-05 09:31:00     781.0\n",
       "2012-06-05 09:32:00     782.0\n",
       "2012-06-05 09:33:00     783.0\n",
       "2012-06-05 09:34:00     784.0\n",
       "2012-06-05 09:35:00     785.0\n",
       "2012-06-05 09:36:00     786.0\n",
       "2012-06-05 09:37:00     787.0\n",
       "2012-06-05 09:38:00     788.0\n",
       "2012-06-05 09:39:00     789.0\n",
       "2012-06-05 09:40:00     790.0\n",
       "2012-06-06 09:30:00    1170.0\n",
       "2012-06-06 09:31:00    1171.0\n",
       "2012-06-06 09:32:00    1172.0\n",
       "2012-06-06 09:33:00    1173.0\n",
       "2012-06-06 09:34:00    1174.0\n",
       "2012-06-06 09:35:00    1175.0\n",
       "2012-06-06 09:36:00    1176.0\n",
       "2012-06-06 09:37:00    1177.0\n",
       "2012-06-06 09:38:00    1178.0\n",
       "2012-06-06 09:39:00    1179.0\n",
       "2012-06-06 09:40:00    1180.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select values between 2 times using between_time method\n",
    "\n",
    "ts.between_time(time(9,30), time(9,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 262, 1276,  144,  175,  246,  545,  500,  390,  226,   49])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To find last known value at 10AM even if there is no 10AM value, we can pass an array of timestamps to the asof method\n",
    "# It obtains an array of the last valid (non-NA) values at/before each timestamp\n",
    "# construct a date range at 10AM for each day and pass that to asof\n",
    "\n",
    "\n",
    "# create sample data set\n",
    "np.random.permutation(len(ts))[700:710]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    4,    5,    8,    9,   13,   14,   16,   17,   18,   20,\n",
       "         21,   23,   24,   25,   28,   29,   30,   31,   32,   34,   37,\n",
       "         38,   41,   42,   44,   45,   46,   53,   58,   59,   61,   63,\n",
       "         65,   67,   68,   69,   70,   73,   74,   75,   76,   78,   81,\n",
       "         82,   84,   87,   89,   90,   92,   93,   94,   95,   96,   97,\n",
       "         98,   99,  105,  106,  107,  108,  110,  111,  112,  114,  115,\n",
       "        117,  118,  121,  122,  125,  126,  128,  130,  131,  133,  134,\n",
       "        137,  139,  141,  142,  143,  144,  145,  146,  147,  148,  149,\n",
       "        150,  153,  154,  155,  156,  158,  160,  164,  165,  167,  168,\n",
       "        169,  171,  173,  174,  176,  178,  179,  180,  181,  182,  183,\n",
       "        185,  187,  193,  196,  197,  199,  201,  205,  206,  209,  211,\n",
       "        212,  213,  216,  217,  219,  220,  224,  225,  226,  227,  229,\n",
       "        230,  231,  236,  238,  241,  243,  244,  245,  246,  247,  248,\n",
       "        250,  251,  256,  257,  259,  260,  261,  262,  265,  267,  268,\n",
       "        273,  276,  278,  279,  280,  281,  282,  285,  287,  288,  290,\n",
       "        294,  295,  297,  298,  299,  300,  303,  304,  305,  307,  316,\n",
       "        317,  319,  320,  322,  323,  324,  325,  326,  329,  330,  331,\n",
       "        332,  338,  339,  340,  341,  342,  343,  344,  345,  348,  351,\n",
       "        353,  354,  355,  356,  357,  358,  359,  360,  361,  362,  363,\n",
       "        366,  367,  369,  372,  373,  376,  377,  379,  380,  381,  383,\n",
       "        384,  385,  386,  389,  390,  391,  394,  396,  398,  399,  400,\n",
       "        401,  406,  407,  408,  410,  413,  416,  418,  421,  422,  423,\n",
       "        424,  425,  426,  431,  432,  433,  435,  437,  438,  441,  442,\n",
       "        444,  448,  449,  450,  451,  455,  456,  457,  458,  460,  461,\n",
       "        464,  466,  468,  470,  471,  472,  473,  474,  475,  476,  481,\n",
       "        485,  487,  488,  489,  490,  491,  494,  496,  497,  501,  502,\n",
       "        505,  506,  508,  509,  511,  512,  517,  519,  520,  522,  523,\n",
       "        527,  529,  532,  534,  536,  537,  540,  541,  545,  546,  548,\n",
       "        549,  551,  553,  554,  555,  557,  558,  559,  560,  563,  566,\n",
       "        569,  570,  571,  572,  574,  576,  578,  579,  580,  581,  583,\n",
       "        585,  588,  590,  591,  592,  593,  596,  597,  598,  599,  604,\n",
       "        606,  607,  609,  611,  614,  618,  620,  621,  622,  624,  625,\n",
       "        628,  629,  631,  633,  637,  639,  640,  642,  644,  645,  646,\n",
       "        647,  648,  650,  652,  653,  654,  660,  662,  663,  664,  665,\n",
       "        666,  670,  671,  674,  675,  676,  681,  683,  684,  685,  686,\n",
       "        688,  689,  691,  692,  694,  695,  696,  697,  699,  700,  701,\n",
       "        702,  705,  708,  710,  711,  715,  716,  717,  718,  723,  725,\n",
       "        726,  727,  730,  732,  733,  734,  736,  737,  738,  740,  741,\n",
       "        744,  745,  747,  749,  752,  753,  754,  756,  757,  758,  761,\n",
       "        764,  765,  767,  768,  770,  771,  773,  775,  777,  781,  782,\n",
       "        783,  784,  785,  786,  787,  793,  795,  796,  797,  799,  802,\n",
       "        804,  805,  806,  809,  810,  812,  814,  815,  816,  817,  818,\n",
       "        819,  823,  824,  827,  828,  829,  830,  833,  834,  835,  836,\n",
       "        837,  840,  842,  844,  849,  853,  856,  857,  858,  861,  863,\n",
       "        864,  865,  867,  868,  869,  872,  874,  875,  877,  878,  879,\n",
       "        880,  887,  892,  897,  898,  900,  902,  905,  906,  907,  908,\n",
       "        909,  913,  915,  917,  918,  919,  920,  922,  923,  924,  927,\n",
       "        929,  931,  932,  933,  934,  936,  940,  944,  945,  946,  948,\n",
       "        949,  950,  953,  954,  959,  961,  963,  964,  965,  966,  968,\n",
       "        969,  970,  971,  973,  975,  976,  979,  982,  984,  988,  989,\n",
       "        991,  992,  993,  995,  996,  999, 1001, 1004, 1005, 1006, 1007,\n",
       "       1008, 1011, 1012, 1013, 1014, 1015, 1016, 1018, 1019, 1021, 1023,\n",
       "       1024, 1025, 1026, 1031, 1033, 1034, 1036, 1037, 1038, 1043, 1046,\n",
       "       1047, 1048, 1053, 1054, 1056, 1057, 1058, 1060, 1061, 1063, 1064,\n",
       "       1065, 1066, 1069, 1073, 1074, 1076, 1078, 1079, 1080, 1081, 1082,\n",
       "       1083, 1084, 1086, 1089, 1090, 1091, 1092, 1094, 1095, 1096, 1097,\n",
       "       1101, 1103, 1105, 1108, 1109, 1110, 1111, 1112, 1114, 1115, 1116,\n",
       "       1120, 1122, 1125, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135,\n",
       "       1136, 1138, 1140, 1141, 1142, 1144, 1154, 1155, 1165, 1167, 1169,\n",
       "       1170, 1172, 1176, 1177, 1178, 1179, 1182, 1184, 1186, 1187, 1189,\n",
       "       1191, 1192, 1193, 1196, 1201, 1203, 1205, 1206, 1207, 1210, 1211,\n",
       "       1215, 1217, 1219, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1229,\n",
       "       1230, 1234, 1236, 1239, 1240, 1241, 1242, 1245, 1246, 1247, 1248,\n",
       "       1250, 1252, 1253, 1254, 1256, 1257, 1258, 1260, 1262, 1263, 1264,\n",
       "       1265, 1269, 1271, 1272, 1274, 1276, 1277, 1278, 1279, 1281, 1283,\n",
       "       1286, 1288, 1289, 1290, 1291, 1293, 1294, 1297, 1299, 1300, 1301,\n",
       "       1302, 1303, 1306, 1310, 1314, 1316, 1318, 1319, 1320, 1321, 1323,\n",
       "       1324, 1325, 1328, 1332, 1333, 1334, 1335, 1336, 1338, 1340, 1344,\n",
       "       1347, 1350, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362,\n",
       "       1365, 1367, 1368, 1369, 1374, 1375, 1377, 1378, 1381, 1383, 1384,\n",
       "       1386, 1387, 1391, 1392, 1393, 1394, 1395, 1396, 1399, 1400, 1402,\n",
       "       1404, 1405, 1407, 1408, 1410, 1411, 1412, 1415, 1416, 1417, 1419,\n",
       "       1421, 1422, 1428, 1430, 1431, 1432, 1435, 1437, 1438, 1441, 1442,\n",
       "       1444, 1445, 1447, 1448, 1452, 1453, 1455, 1461, 1464, 1465, 1467,\n",
       "       1469, 1472, 1474, 1477, 1479, 1480, 1482, 1483, 1485, 1487, 1491,\n",
       "       1494, 1495, 1499, 1500, 1501, 1503, 1505, 1509, 1511, 1512, 1515,\n",
       "       1519, 1521, 1524, 1525, 1526, 1528, 1530, 1533, 1536, 1537, 1538,\n",
       "       1540, 1541, 1542, 1543, 1546, 1547, 1550, 1553, 1554, 1556, 1557,\n",
       "       1558, 1559])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.random.permutation(len(ts))[700:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-06-01 09:30:00    0.0\n",
       "2012-06-01 09:31:00    1.0\n",
       "2012-06-01 09:32:00    2.0\n",
       "2012-06-01 09:33:00    3.0\n",
       "2012-06-01 09:34:00    4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an array of random numbers\n",
    "indexer = np.sort(np.random.permutation(len(ts))[700:])\n",
    "\n",
    "irr_ts = ts.copy()\n",
    "irr_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-06-01 09:30:00    0.0\n",
       "2012-06-01 09:31:00    NaN\n",
       "2012-06-01 09:32:00    2.0\n",
       "2012-06-01 09:33:00    NaN\n",
       "2012-06-01 09:34:00    4.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irr_ts[indexer] = np.nan\n",
    "irr_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-06-01 09:50:00    20.0\n",
      "2012-06-01 09:51:00     NaN\n",
      "2012-06-01 09:52:00     NaN\n",
      "2012-06-01 09:53:00     NaN\n",
      "2012-06-01 09:54:00     NaN\n",
      "2012-06-01 09:55:00    25.0\n",
      "2012-06-01 09:56:00     NaN\n",
      "2012-06-01 09:57:00     NaN\n",
      "2012-06-01 09:58:00     NaN\n",
      "2012-06-01 09:59:00     NaN\n",
      "2012-06-01 10:00:00     NaN\n",
      "dtype: float64\n",
      "DatetimeIndex(['2012-06-01 10:00:00', '2012-06-04 10:00:00',\n",
      "               '2012-06-05 10:00:00', '2012-06-06 10:00:00'],\n",
      "              dtype='datetime64[ns]', freq='B')\n",
      "2012-06-01 10:00:00      25.0\n",
      "2012-06-04 10:00:00     414.0\n",
      "2012-06-05 10:00:00     810.0\n",
      "2012-06-06 10:00:00    1199.0\n",
      "Freq: B, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Selecting time series between 9:50 to 10 on June 1st, 2012\n",
    "\n",
    "print irr_ts['2012-06-01 09:50':'2012-06-01 10:00']\n",
    "\n",
    "# By passing an array of timestamps to the asof method, \n",
    "# we will obtain an array of the last valid (non-NA) values at or before each time stamp of the array\n",
    "\n",
    "# Construct a date range at 10AM for each day and pass that to asof\n",
    "selection = pd.date_range('2012-06-01 10:00', periods=4, freq='B') # Business weekdays only\n",
    "print selection\n",
    "\n",
    "# find values\n",
    "print irr_ts.asof(selection) # Returns the last value before or at the time stamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Together Data Sources (aka Splicing)\n",
    "\n",
    "Use cases:\n",
    "- Switching from one data source to another at a specific point in time\n",
    "- Filling in missing values in a time series using another time series\n",
    "- Completely replacing the data for a subset of variables or values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Case 1. Switching from one time series to another\n",
    "\n",
    "It's a matter of splicing (combining) together two time series or DataFrame using `pandas.concat`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              a    b    c\n",
      "2012-06-12  1.0  1.0  1.0\n",
      "2012-06-13  1.0  1.0  1.0\n",
      "2012-06-14  1.0  1.0  1.0\n",
      "2012-06-15  1.0  1.0  1.0\n",
      "2012-06-16  1.0  1.0  1.0\n",
      "2012-06-17  1.0  1.0  1.0\n",
      "              a    b    c    d\n",
      "2012-06-13  2.0  2.0  2.0  2.0\n",
      "2012-06-14  2.0  2.0  2.0  2.0\n",
      "2012-06-15  2.0  2.0  2.0  2.0\n",
      "2012-06-16  2.0  2.0  2.0  2.0\n",
      "2012-06-17  2.0  2.0  2.0  2.0\n",
      "2012-06-18  2.0  2.0  2.0  2.0\n"
     ]
    }
   ],
   "source": [
    "data1=DataFrame(np.ones((6,3), dtype=float),\n",
    "                columns =['a','b','c'],\n",
    "                index=pd.date_range('6/12/2012', periods=6))\n",
    "\n",
    "data2=DataFrame(np.ones((6,4), dtype=float) * 2,\n",
    "                columns=['a','b','c','d'],\n",
    "                index=pd.date_range('6/13/2012', periods=6))\n",
    "\n",
    "print data1\n",
    "print data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-06-12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              a    b    c    d\n",
       "2012-06-12  1.0  1.0  1.0  NaN\n",
       "2012-06-13  1.0  1.0  1.0  NaN\n",
       "2012-06-14  1.0  1.0  1.0  NaN\n",
       "2012-06-15  2.0  2.0  2.0  2.0\n",
       "2012-06-16  2.0  2.0  2.0  2.0\n",
       "2012-06-17  2.0  2.0  2.0  2.0\n",
       "2012-06-18  2.0  2.0  2.0  2.0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spliced = pd.concat([data1.loc[:'2012-06-14'],data2.loc['2012-06-15':]]) # combined data sets after certain dates\n",
    "spliced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in missing gaps with another time series (using combine_first, update) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-06-12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              a    b    c    d\n",
       "2012-06-12  1.0  1.0  1.0  NaN\n",
       "2012-06-13  1.0  1.0  1.0  2.0\n",
       "2012-06-14  1.0  1.0  1.0  2.0\n",
       "2012-06-15  2.0  2.0  2.0  2.0\n",
       "2012-06-16  2.0  2.0  2.0  2.0\n",
       "2012-06-17  2.0  2.0  2.0  2.0\n",
       "2012-06-18  2.0  2.0  2.0  2.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using combine_first, we can bring in data from before the splice point to extend the history for 'd' item\n",
    "# we start with data1 then fill in gaps with data2\n",
    "\n",
    "spliced_filled = spliced.combine_first(data2)\n",
    "spliced_filled\n",
    "\n",
    "# Since data2 does not have any values for 2012-06-12, no values are filled on that day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-06-12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              a    b    c    d\n",
       "2012-06-12  1.0  1.0  1.0  NaN\n",
       "2012-06-13  1.0  1.0  1.0  2.0\n",
       "2012-06-14  1.0  1.0  1.0  2.0\n",
       "2012-06-15  2.0  2.0  2.0  2.0\n",
       "2012-06-16  2.0  2.0  2.0  2.0\n",
       "2012-06-17  2.0  2.0  2.0  2.0\n",
       "2012-06-18  2.0  2.0  2.0  2.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame's update mehtod for performing in-place updates. \n",
    "# pass overwrite=False to ONLY fill in gaps\n",
    "\n",
    "spliced.update(data2, overwrite=False)\n",
    "spliced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace data for a subset of columns (use above techniques or set columns directly using indexing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-06-12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              a    b    c    d\n",
       "2012-06-12  1.0  1.0  1.0  NaN\n",
       "2012-06-13  1.0  1.0  1.0  2.0\n",
       "2012-06-14  1.0  1.0  1.0  2.0\n",
       "2012-06-15  1.0  2.0  1.0  2.0\n",
       "2012-06-16  1.0  2.0  1.0  2.0\n",
       "2012-06-17  1.0  2.0  1.0  2.0\n",
       "2012-06-18  NaN  2.0  NaN  2.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_spliced=spliced.copy()\n",
    "\n",
    "cp_spliced[['a','c']] = data1[['a','c']]\n",
    "\n",
    "cp_spliced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return indexes and Cumulative Returns\n",
    "\n",
    "**returns** refers to percent changes in the price.\n",
    "\n",
    "For example, consider price data for AAPL from 2011-2012. For Apple, computing the cumulative percent % between 2 points in time requires computing only the percent change in the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import yahoo_finance\n",
    "from yahoo_finance import Share\n",
    "\n",
    "start=datetime.datetime(2011,1,1)\n",
    "end=datetime.datetime(2012,12,31)\n",
    "\n",
    "Apple = Share('AAPL')\n",
    "\n",
    "# THIS HAS BE DEPRACATED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group transforms and analysis\n",
    "\n",
    "For the most part, **`xrange`** and **`range`** are the exact same in terms of functionality. They both provide a way to generate a list of integers for you to use, however you please. The only difference is that range returns a Python list object and xrange returns an xrange object. Okay, now what does that mean? Another good question. That means that if you have a really gigantic range you'd like to generate a list for, say one billion, xrange is the function to use. This is especially true if you have a really memory sensitive system such as a cell phone that you are working with, as range will use as much memory as it can to create your array of integers, which can result in a MemoryError and crash your program. It's a memory hungry beast. \n",
    "\n",
    "**`random.choice(seq)`**\n",
    "Return a random element from the non-empty sequence seq. If seq is empty, raises IndexError.\n",
    "\n",
    "source: http://pythoncentral.io/how-to-use-pythons-xrange-and-range/\n",
    "\n",
    "Let's consider a collection of hypothetical stock portfolios. Randomly genreate a broad univeerse of 2000 tickers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random; random.seed(0)\n",
    "import string\n",
    "\n",
    "N=1000\n",
    "def rands(n):\n",
    "    choices=string.ascii_uppercase\n",
    "    return ''.join([random.choice(choices) for _ in xrange(n)])\n",
    "\n",
    "tickers=np.array([rands(5) for _ in xrange(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame containing 3 columns representing hypothetical, random portfolios\n",
    "\n",
    "M = 500\n",
    "df = DataFrame({'Momentum': np.random.randn(M) / 200 + 0.03,\n",
    "                'Value': np.random.randn(M) / 200 + 0.08,\n",
    "                'ShortInterest' : np.random.randn(M) / 200 -0.02},\n",
    "               index=tickers[:M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 0 1 1\n",
      " 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1 0\n",
      " 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0\n",
      " 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 0 0\n",
      " 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0\n",
      " 0 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 1 1 0 1 0 1 1 0 1 0 0 1\n",
      " 0 0 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 0 1 1 0 0 0 0 1 1 1\n",
      " 1 0 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 1\n",
      " 1 0 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 1 0 0\n",
      " 1 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 0 1 0 0 0 0 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 0 0 1 1 0\n",
      " 1 1 1 1 0 0 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 1 0 1 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 1 0 1\n",
      " 1 1 0 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 1 1 0 1\n",
      " 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 0 1\n",
      " 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1\n",
      " 0 0 1 1 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 1 0 1 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0\n",
      " 1 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 1 0 0 1 0 0 0 1 1 0 1 1 1 0 1 0 1 0 0 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 0 0\n",
      " 1 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1\n",
      " 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1 1 0 0 0 0 1 1 0 1\n",
      " 1 1 0 0 1 0 1 1 1 0 0 0 1 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0\n",
      " 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 1 1 1 0 0 1 0\n",
      " 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 0 1 0\n",
      " 0]\n",
      "VTKGN     FINANCIAL\n",
      "KUHMP    TECHNOLOGY\n",
      "XNHTQ     FINANCIAL\n",
      "GXZVX     FINANCIAL\n",
      "ISXRM     FINANCIAL\n",
      "Name: industry, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a random industry classification for the tickers. Keep it to 2 industries, storing hte mapping in a series\n",
    "\n",
    "ind_names = np.array(['FINANCIAL','TECHNOLOGY'])\n",
    "sampler = np.random.randint(0,len(ind_names), N)  # generate random integers between 0 and 1 N times (2000)\n",
    "industries = Series(ind_names[sampler], index=tickers, name='industry') \n",
    "\n",
    "print sampler\n",
    "print industries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Momentum</th>\n",
       "      <th>ShortInterest</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FINANCIAL</th>\n",
       "      <td>0.029904</td>\n",
       "      <td>-0.019718</td>\n",
       "      <td>0.079951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TECHNOLOGY</th>\n",
       "      <td>0.029566</td>\n",
       "      <td>-0.020486</td>\n",
       "      <td>0.079556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Momentum  ShortInterest     Value\n",
       "industry                                     \n",
       "FINANCIAL   0.029904      -0.019718  0.079951\n",
       "TECHNOLOGY  0.029566      -0.020486  0.079556"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by industries and carry out group aggregation and transformation\n",
    "\n",
    "by_industry = df.groupby(industries)\n",
    "\n",
    "by_industry.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Momentum</th>\n",
       "      <th colspan=\"5\" halign=\"left\">ShortInterest</th>\n",
       "      <th colspan=\"8\" halign=\"left\">Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FINANCIAL</th>\n",
       "      <td>237.0</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>0.013224</td>\n",
       "      <td>0.025989</td>\n",
       "      <td>0.029826</td>\n",
       "      <td>0.033719</td>\n",
       "      <td>0.051079</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-0.019718</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016181</td>\n",
       "      <td>-0.002213</td>\n",
       "      <td>237.0</td>\n",
       "      <td>0.079951</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>0.067201</td>\n",
       "      <td>0.076878</td>\n",
       "      <td>0.080311</td>\n",
       "      <td>0.082923</td>\n",
       "      <td>0.089894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TECHNOLOGY</th>\n",
       "      <td>263.0</td>\n",
       "      <td>0.029566</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.015618</td>\n",
       "      <td>0.026520</td>\n",
       "      <td>0.029430</td>\n",
       "      <td>0.033121</td>\n",
       "      <td>0.041820</td>\n",
       "      <td>263.0</td>\n",
       "      <td>-0.020486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017437</td>\n",
       "      <td>-0.008644</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.079556</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>0.063003</td>\n",
       "      <td>0.076151</td>\n",
       "      <td>0.079660</td>\n",
       "      <td>0.083015</td>\n",
       "      <td>0.093622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Momentum                                                    \\\n",
       "              count      mean       std       min       25%       50%   \n",
       "industry                                                                \n",
       "FINANCIAL     237.0  0.029904  0.005565  0.013224  0.025989  0.029826   \n",
       "TECHNOLOGY    263.0  0.029566  0.004792  0.015618  0.026520  0.029430   \n",
       "\n",
       "                               ShortInterest              ...               \\\n",
       "                 75%       max         count      mean    ...          75%   \n",
       "industry                                                  ...                \n",
       "FINANCIAL   0.033719  0.051079         237.0 -0.019718    ...    -0.016181   \n",
       "TECHNOLOGY  0.033121  0.041820         263.0 -0.020486    ...    -0.017437   \n",
       "\n",
       "                      Value                                                    \\\n",
       "                 max  count      mean       std       min       25%       50%   \n",
       "industry                                                                        \n",
       "FINANCIAL  -0.002213  237.0  0.079951  0.004671  0.067201  0.076878  0.080311   \n",
       "TECHNOLOGY -0.008644  263.0  0.079556  0.005254  0.063003  0.076151  0.079660   \n",
       "\n",
       "                                \n",
       "                 75%       max  \n",
       "industry                        \n",
       "FINANCIAL   0.082923  0.089894  \n",
       "TECHNOLOGY  0.083015  0.093622  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_industry.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Momentum</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ShortInterest</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FINANCIAL</th>\n",
       "      <td>-1.818049e-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.133645e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.592394e-15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TECHNOLOGY</th>\n",
       "      <td>1.602858e-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.318382e-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.626633e-16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Momentum      ShortInterest              Value     \n",
       "                    mean  std          mean  std          mean  std\n",
       "industry                                                           \n",
       "FINANCIAL  -1.818049e-15  1.0  1.133645e-16  1.0  2.592394e-15  1.0\n",
       "TECHNOLOGY  1.602858e-15  1.0  2.318382e-15  1.0 -4.626633e-16  1.0"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by defining transformation functions, it's easy to transform these portfolios by industry\n",
    "# For example, standardizing with z-score is widely used in equity portfolio construction\n",
    "\n",
    "# Within-Industry Standardize\n",
    "def zscore(group):\n",
    "    return (group - group.mean()) / group.std()\n",
    "\n",
    "df_stand = by_industry.apply(zscore)\n",
    "\n",
    "df_stand.groupby(industries).agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Momentum  ShortInterest  Value\n",
      "VTKGN     142.0          108.0  210.0\n",
      "KUHMP     101.0          123.0   63.0\n",
      "XNHTQ      92.0          118.0  125.0\n",
      "GXZVX     227.0           35.0  141.0\n",
      "ISXRM     188.0          102.0   42.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Momentum</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ShortInterest</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FINANCIAL</th>\n",
       "      <td>1.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TECHNOLOGY</th>\n",
       "      <td>1.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>263.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Momentum        ShortInterest        Value       \n",
       "                min    max           min    max   min    max\n",
       "industry                                                    \n",
       "FINANCIAL       1.0  237.0           1.0  237.0   1.0  237.0\n",
       "TECHNOLOGY      1.0  263.0           1.0  263.0   1.0  263.0"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can rank all tickers per column value\n",
    "ind_rank = by_industry.rank(ascending=False) # Rank but not in order\n",
    "print ind_rank.head()\n",
    "\n",
    "ind_rank.groupby(industries).agg(['min','max'])  #min, max rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 500 entries, VTKGN to PTDQE\n",
      "Data columns (total 3 columns):\n",
      "Momentum         500 non-null float64\n",
      "ShortInterest    500 non-null float64\n",
      "Value            500 non-null float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 35.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# rank and standardize by chainnig together rank and zscore\n",
    "\n",
    "by_industry.apply(lambda x: zscore(x.rank())).info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
